\chapter{The Cold-Start Problem in AccelSim}\label{ch:sim-analysis}

We can now safely conclude that GPGPU hardware and workloads suffer from cold caches.
In this chapter, we will attempt to validate the existence of the cold-start problem when simulating.
To this end, we will use the AccelSim framework, with a similar configuration to the hardware we used in the previous chapter.

\section{Simulation setup}\label{sec:simulation-setup}
The simulator we will be using is AccelSim\cite{accelsim}.
As discussed in \Cref{sec:gpu-simulation}, AccelSim uses the GPGPU-Sim\cite{gpgpu-sim} system to perform actual simulation.
However, we are able to speed everything up by avoiding full-functional simulation.
To achieve this, we use pre-generated traces, which can be replayed in the simulator.
This also means that we can just use compiled binaries, not needing any source at all.

In the experiments discussed below, we have used the GPGPU-Sim configuration for the NVIDIA GeForce RTX 3070 hardware (running on SM 86; as described in\ \cite{nvidia-wp}).
Some of its configuration parameters are shown in \Cref{fig:sim_config}.

\begin{figure}[ht]
    \centering
    \input{figures/simulated/gpu_config}
    \caption{Simulator configuration parameters}
    \label{fig:sim_config}
\end{figure}

Just like with the hardware analysis, we will be simulating each workload twice: once with the cache flushed between kernel invocations, and once without.
This is a feature that AccelSim natively supports, using the \verb|-flush-l1 -flush-l2| arguments.

\FloatBarrier
\section{Preparation}\label{sec:preparation}
In order to simulate each workload, we needed to profile them again.
In the previous chapter, we used NVIDIA's Nsight Compute tool, which is a lightweight profiler.
However, we need a cycle-level trace for the simulator, which means that we will need something more powerful.

Preparing a workload for simulation has two big steps:
\begin{enumerate}
    \item \textit{Profiling:} AccelSim requires a cycle-level trace.
    We will discuss the exact process below, in \Cref{subsec:profiling-phase}.
    \item \textit{Post-processing:} the trace, as generated in the profiling phase, is not yet fit for simulation.
    AccelSim includes a post-processing tool, which allows us to convert the trace.
    We will also shortly discuss this in \Cref{subsec:profiling-phase}.
\end{enumerate}

\subsection{Profiling phase}\label{subsec:profiling-phase}
One of the components of the AccelSim framework is an NVBit\cite{nvbit} tool.

NVBit is a framework, developed by NVIDIA, to instrument CUDA applications.
It allows us to, among others, catch certain events (like kernel invocations), and insert additional instructions and calls in a kernel.
Each NVBit tool is compiled into a shared library, which is then injected into the application.
To this end, the \verb|LD_PRELOAD| trick is used; which allows us to load a shared library before any other library.

AccelSim's tool is in the \verb|util/tracer_nvbit/tracer_tool| directory.
It roughly works like this:
\begin{enumerate}
    \item The runtime will register that the NVBit tool has declared the \verb|nvbit_at_cuda_event| function.
    At each CUDA event, this function will be invoked, with details on the event.
    \item When the function is invoked, it checks if it is due to the invocation of a kernel that has not been instrumented yet.
    If this is the case, the tool will instrument the kernel by adding a call to \verb|instrument_inst| before each instruction in the kernel.
    The arguments it passes to this function call depend on the instruction that is being instrumented.
    \item Each time \verb|instrument_inst| is called, it receives some information about the instruction that is to come.
    This information is written on a channel to another thread, which will write it to a file.
\end{enumerate}

In this way, a directory with a trace file for each kernel is generated.
These trace files contain an instruction-level trace for each kernel.
Additionally, it generates \verb|kernelslist|, an additional file containing a reference to each file generated.

However, due to interleaving of threads, these traces are not in the correct order yet for the simulator.
The post-processing tool, in the \verb|util/tracer_nvbit/tracer_tool/traces-processing| directory, will make sure that the traces are ready to be used.
It reads each trace file listed in the given \verb|kernelslist| file, sorting the instructions by thread block.
This makes sure that the simulator can quickly access the instructions it needs to simulate a given thread block.

These sorted traces are each written to their own new file, while an additional \verb|kernelslist.g| file is generated, referencing the processed traces.

\FloatBarrier
\section{Simulation results}\label{sec:simulation-results}
In this section, we will show that the impact of this problem persists in the AccelSim simulator.
However, one of the first things we have noticed is that the simulator is affected much differently from the real hardware.

Due to the inherent overhead in simulating GPUs, we had to limit the number of kernels we could simulate(in this case, up to 130, which fit the DCT nicely, but served as a cutoff for 3D-UNet), as well as which workloads we could focus on.
The DCT and 3D U-Net workloads were selected for this analysis, as they showed promising results in the hardware analysis.
Following our discussion about inter-kernel data reuse, we also included the OceanFFT workload (from the CUDA SDK) in this analysis.

\begin{figure}[ht]
    \centering
    \append{./figures/simulated/full_dct_ocean_unet_sim.pgf}
    \append{./figures/simulated/full_dct_ocean_unet_table}
    \caption{Weighted IPC differences}
    \label{fig:sim_ipc_diff}
\end{figure}

The graphs in \Cref{fig:sim_ipc_diff} show the results of this analysis.
They follow the same structure as \Cref{fig:weight_ipc_diff} from the hardware analysis: showing weighted IPC differences for each workload.
The first thing we noticed is that the simulator results are very different from the hardware results.
Where 3D U-Net had kernels with a relative IPC difference of over 15\% in hardware, the differences in the simulator cap out around 5\%.
For DCT we notice a similar trend: the simulator results are much lower than the hardware results.
Where the hardware results showed that more than 50\% of the workload suffered from at least 20\% in IPC difference, the simulator results give a maximum of 15\% (worth less than 1\% of the workload).

\subsection{OceanFFT}\label{subsec:oceanfft}
In this figure, the OceanFFT workload really stands out, compared to the other workloads.
When looking into the structure of the OceanFFT workload, we noticed that it consists of only five kernels, of which one (kernel \#2) is significantly affected by the cold-start problem.
The other four kernels (kernel \#1, \#3, \#4, and \#5) are not affected by the cold-start problem at all (all of them suffering less than 0.5\% relative IPC difference), as you can see in \Cref{fig:ocean_kernels}.
We also compared the data reuse factors for each of these kernels, and they are both very irregular, and a lot lower than DCT\@.

\begin{figure}[ht]
    \centering
    \appendW{figures/simulated/ocean_kernels}{}
    \caption{OceanFFT kernels}
    \label{fig:ocean_kernels}
\end{figure}

In addition, we also noticed that OceanFFT suffers from another oddity: its kernels run faster with flushed caches.
Especially the second kernel, whose IPC increases with almost 50\% if we flush the caches, as you can see in \Cref{fig:ocean_issue}.

We assume that this might be caused by the fact that the second kernel only reuses a small fraction of memory addresses used by the first one.
In that case, the caches would be filled with data that is not used by the second kernel, causing the (simulated) GPU to waste precious cycles on searching the caches for data that is not there.

\begin{figure}[ht]
    \centering
    \appendW{figures/simulated/ocean_issue}{}
    \caption{OceanFFT IPC values}
    \label{fig:ocean_issue}
\end{figure}


\FloatBarrier
\section{Simulator conclusion}\label{sec:simulator-conclusion}
Once again, we see that the cold-start problem persists.
However, it is much less severe in the simulator; the maximum impact of the cold-start problem on 3D-UNet drops from over 20\% to around 15\%.
For DCT, this shows even more, as a large part of the workload (just shy of 60\%) suffered from at least 20\% of IPC difference in hardware, while in the simulator, not a single kernel suffers that much.
Instead, the differences cap out around 15\%, with less than 1\% of the workload suffering from that.

In the next chapter, we will start looking for a mitigation, limiting the impact of the cold-start problem.
We will mostly analyze the DCT workload, due to its short runtime and thus reasonable runtime.
Two main factors will exclude the OceanFFT workload from this analysis: firstly, the most interesting kernel is the second one, limiting one of our mitigations.
Secondly, its oddity (the fact that it runs faster with flushed caches) makes it a bad candidate for our second mitigation.